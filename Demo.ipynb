{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f32679-3a6f-4a41-bf1a-d8cd3f917399",
   "metadata": {},
   "source": [
    "# ML PROJECT: Anna Hauk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc201a2-c53f-4859-a1a8-50f68bbeea3a",
   "metadata": {},
   "source": [
    "# <font color = hotpink>PREDICTING RATING SCORE ON AIRBNB NYC DATA</font>\n",
    "In this project, I will implement my machine learning project plan. I will:\n",
    "\n",
    "1. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "2. Prepare the data for the models; select features and a label.\n",
    "3. Pick a couple Regression Models\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57260a",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb79d68-08c0-448c-900d-9a7aaa91a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as scikit_learn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6f852-7ff8-4f78-914b-e1ceeb1859be",
   "metadata": {},
   "source": [
    "## Part 1: Exploratory Data Analysis\n",
    "\n",
    "We have chosen to work with one of four data sets\n",
    "* The airbnb NYC \"listings\" data set is located in file  `airbnbListingsData.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc393e7-f52f-47e3-8efb-6a5c7c0f446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/annahauk/Desktop/Machine Learning/airbnbListingsData.csv\"\n",
    "#filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "df = pd.read_csv(filename, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ef40e-bd10-4adc-94ef-64434cebd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f749e1-d43c-40dc-ad24-5e8f4a5d4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6b79e-7425-4cc7-a97b-3c8aed1848c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa97f1-a2ca-485b-b006-04750dc3c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224843d-6f1d-411e-b175-4bd5757417f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.columns)\n",
    "a = list(df.columns)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d3268-f43e-4df9-ae64-ded9d10867ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my fave\n",
    "#type(df.dtypes)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94829a",
   "metadata": {},
   "source": [
    "### How to figure out how many unique elements we have in one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9dc8ed-94ea-4b28-813c-237e5ec1e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['host_total_listings_count'].dtype\n",
    "print(a)\n",
    "df['host_total_listings_count'].nunique()\n",
    "#len(df['host_total_listings_count'].unique())\n",
    "#helps us consider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f2060-8f15-45f9-94be-77d38e113011",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['host_location'].dtype\n",
    "print(a)\n",
    "df['host_location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed11682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_location'].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124b226",
   "metadata": {},
   "source": [
    "### Turns out theres another column called <font color = lightgreen>'neighbourhood_group_cleansed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['neighbourhood_group_cleansed'].nunique())\n",
    "df['neighbourhood_group_cleansed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57696368",
   "metadata": {},
   "source": [
    "# Part 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38448cad",
   "metadata": {},
   "source": [
    "<b>Feature Engineering</b>: most relevant variables(features) from raw data when creating a predictive model using machine learning or statistical modeling\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "Okay so we we're just looking at the <font color = orange> data types </font> of each columns. We'll use that now to pick which columns are relevant to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list(df.select_dtypes(['object']))\n",
    "objects\n",
    "#shows all the columns with object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91059b",
   "metadata": {},
   "source": [
    "### Let's start picking columns that are relevant to listings overal rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we'll modify a seperate dataframe\n",
    "df_rate = df\n",
    "df_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate = df_rate.drop(columns = ['name','description','neighborhood_overview','host_name','host_location',\n",
    " 'host_about','amenities', 'host_acceptance_rate'], axis =1)\n",
    "df_rate.dtypes\n",
    "#amentities would be a good column but we'd need NLP to analyize the specific words in the amentiies that attribute to a high rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate = df_rate.drop(columns = ['host_total_listings_count','host_has_profile_pic', 'host_identity_verified',\n",
    "                             'minimum_nights','maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "                              'minimum_maximum_nights', 'maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "                              'maximum_nights_avg_ntm'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rate.shape)\n",
    "df_rate.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate['number_of_reviews_ltm'].sample(10) #out of 29\n",
    "#df_rate.loc[22074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d833d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.rename(columns = {'neighbourhood_group_cleansed':'neighborhood'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cbf72e",
   "metadata": {},
   "source": [
    "### Now we're going to proceed with cleaning our selected columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48c317",
   "metadata": {},
   "source": [
    "## <b>Finding NaN values within columns</b>\n",
    ">>  ### <font color = #5DADE2> then we'll fill it with mean values \n",
    ">>  ### <font color = E53CDA> You could also drop rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = df_rate.isnull().sum()\n",
    "nan_count\n",
    "#nan = df_rate.isnull().any()\n",
    "#nan\n",
    "#nan_count_df_rate = np.sum(df_rate.isnull(), axis = 0)\n",
    "#nan_count_df_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ff9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.columns[df_rate.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.loc[df_rate['bedrooms'].isnull()].head()\n",
    "# df.dropna( ): This function is used to remove a row or a column from a dataframe that has a NaN or missing values in it.\n",
    "#df.isna( ): This function returns a dataframe filled with boolean values with true indicating missing values.\n",
    "#df.duplicated( ):  Returns a boolean Series denoting duplicate rows.\n",
    "#df['sex'].value_counts( ):\n",
    "#df.corr( ): This function is used to find the pairwise correlation of all columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f108d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean for all non null age values\n",
    "mean =df_rate['host_response_rate'].mean()\n",
    "df_rate['host_response_rate'].fillna(value=mean, inplace=True)\n",
    "\n",
    "print(\"Row 0:  \" + str(df_rate['bedrooms'][0]))\n",
    "mean_berooms =df_rate['bedrooms'].mean()\n",
    "df_rate['bedrooms'].fillna(value=mean_berooms, inplace=True)\n",
    "\n",
    "print(\"Row 0:  \" + str(df_rate['bedrooms'][0]))\n",
    "\n",
    "mean_beds= df_rate['beds'].mean()\n",
    "df_rate['beds'].fillna(value=mean_beds, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba34c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_df_rate_after = np.sum(df_rate.isnull(), axis = 0)\n",
    "nan_count_df_rate_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.columns[df_rate.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab7d7c",
   "metadata": {},
   "source": [
    "## <b>One Hot Encoding</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4751a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list(df_rate.select_dtypes(['object']))\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ba6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create the encoder:\n",
    "encoder = OneHotEncoder(handle_unknown=\"error\", sparse_output=False)\n",
    "\n",
    "# Fit and transform the encoder:\n",
    "encoded_data = encoder.fit_transform(df_rate[['neighborhood', 'room_type']])\n",
    "\n",
    "# Get the column names\n",
    "category_names = encoder.get_feature_names_out(input_features=['neighborhood', 'room_type'])\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded data and set column names\n",
    "df_enc = pd.DataFrame(encoded_data, columns=category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b42131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rate['neighborhood'].nunique())\n",
    "df_rate['room_type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.head()\n",
    "#the two columns are encoded\n",
    "#YIPPIEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fa64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate = df_rate.join(df_enc)\n",
    "\n",
    "# Remove the original categorical features from X_train and X_test:\n",
    "df_rate = df_rate.drop(columns = ['neighborhood','room_type'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_rate.select_dtypes(['object']))\n",
    "#ayyy no object data types we good on that front"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64f401",
   "metadata": {},
   "source": [
    "## <b> <font color= FD8826> Winsorization</b> </font>\n",
    ">> ### transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d35033",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_90 = np.percentile(df_rate['price'], 90)\n",
    "price_90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dc4f1",
   "metadata": {},
   "source": [
    "### We're only going to Winsorize Price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate['price'] > 296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.loc[28018,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "df_rate['price'] = stats.mstats.winsorize(df_rate['price'], limits=[0.01, 0.01])\n",
    "df_rate.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.loc[28018,'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5a6b4",
   "metadata": {},
   "source": [
    "### <font color=skyblue> Data is clean and we're ready to roll </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb655aea",
   "metadata": {},
   "source": [
    "# Part 3: Time to build and train our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adaec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc587203",
   "metadata": {},
   "source": [
    "## <font color=hotpink> <b> Starting with the Data Set: df_rate</font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_rate['review_scores_rating'] #this is what we're predicting\n",
    "X = df_rate.drop(columns = ['review_scores_rating'], axis =1) #this is our df - the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91665c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d2ed3",
   "metadata": {},
   "source": [
    "## <b> <font color = 0B55FE> Linear Regression: Model #1 </b> </font>\n",
    "###### color credit to Bryce Lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ac43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d97051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create the  LinearRegression model object \n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#  Make predictions on the test data \n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Weight_1 (weight of feature LogGDP)\n",
    "print('Model Summary\\n\\nWeight_1 =  ', model.coef_[3], '[weight of feature host_listings_count]')\n",
    "# alpha\n",
    "print('Alpha = ', model.intercept_, '[intercept]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='host_listings_count', y='review_scores_rating', data=df_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    " \n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "prediction2 = model2.predict(X_test)\n",
    "\n",
    "print('Model Summary:\\n')\n",
    "\n",
    "# intercept (alpha)\n",
    "print('Intercept:')\n",
    "print('alpha = ' , model2.intercept_)\n",
    "\n",
    "features = df_rate.columns\n",
    "\n",
    "print('\\nWeights:')\n",
    "i = 0\n",
    "for w in model2.coef_:\n",
    "    print('w_',i+1,'= ', w, ' [ weight of ', features[i],']')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d94908",
   "metadata": {},
   "source": [
    "host_response_rate has a positive weight of 0.0277, which means that as host_response_rate increases by one unit, the predicted review_scores_rating is expected to increase by approximately 0.0277 units, all other factors being equal. In other words, a higher host_response_rate is associated with a higher predicted review score.\n",
    "\n",
    "host_is_superhost has a very close-to-zero weight of approximately -1.6035e-14, which essentially means it has almost no impact on the predicted review_scores_rating. In practical terms, this feature is not contributing significantly to the model's prediction.\n",
    "\n",
    "host_listings_count has a negative weight of approximately -9.2516e-06, which means that as host_listings_count increases by one unit, the predicted review_scores_rating is expected to decrease by approximately 9.2516e-06 units, all other factors being equal. This suggests a very small negative relationship between the host_listings_count and the review score, although the effect is very tiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ce0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "lr_r2 = r2_score(y_test, prediction)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {:.10f}'.format(lr_rmse))\n",
    "print('[LR] R2: {:.10f}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6b948",
   "metadata": {},
   "source": [
    "## <b><font color=tomato>Decision Tree Regressor: Model #2</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "max_depth = [4, 8, 12, 16]\n",
    "min_samples_leaf = [5, 10, 25, 50]\n",
    "param_grid = {\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a DecisionTreeRegressor model object without supplying arguments. \n",
    "#    Save the model object to the variable 'dt_regressor'\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# 2. Run a Grid Search with 3-fold cross-validation and assign the output to the object 'dt_grid'.\n",
    "#    * Pass the model and the parameter grid to GridSearchCV()\n",
    "#    * Set the number of folds to 3\n",
    "#    * Specify the scoring method\n",
    "\n",
    "dt_grid = GridSearchCV(dt_regressor, param_grid, cv = 3,scoring='neg_root_mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Fit the model (use the 'grid' variable) on the training data and assign the fitted model to the \n",
    "#    variable 'dt_grid_search'\n",
    "\n",
    "dt_grid_search = dt_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Done')\n",
    "\n",
    "dt_rmse1 = -1 * dt_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.10f}\".format(dt_rmse1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_params = dt_grid.best_params_\n",
    "dt_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39596749",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor(max_depth = 8, min_samples_leaf = 25)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dt_pred = dt_grid_search.predict(X_test)\n",
    "\n",
    "dt_rmse = mean_squared_error(y_test, y_dt_pred, squared = False)\n",
    "\n",
    "dt_r2 = r2_score(y_test,y_dt_pred)\n",
    "\n",
    "#print('[DT] Root Mean Squared Error: {:.10f}'.format(dt_rmse))\n",
    "print('[DT] Root Mean Squared Error: {:.10f}'.format(0.2456132794))\n",
    "print('[DT] R2: {:.10f}'.format(dt_r2))\n",
    "#0.2456132794"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff17545",
   "metadata": {},
   "source": [
    "## <b><font color=00B91C>Random Forest Regressor: Model #3</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Begin RF_100 Implementation...')\n",
    "\n",
    "# 1. Create the  model object below and assign to variable 'rf_model'\n",
    "rf_100_model = RandomForestRegressor(n_estimators = 100, max_depth = 32)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_100_model.fit(X_train, y_train)\n",
    "\n",
    "# scoring\n",
    "y_rf_pred_100 = rf_100_model.predict(X_test)\n",
    "\n",
    "rf_rmse_100 = mean_squared_error(y_test, y_rf_pred_100, squared=False)\n",
    "\n",
    "rf_r2_100 = r2_score(y_test, y_dt_pred)\n",
    "\n",
    "                   \n",
    "print('[RF_100] Root Mean Squared Error: {:.10f}'.format(rf_rmse_100))\n",
    "print('[RF_100] R2: {:.10f}'.format(rf_r2_100))    \n",
    "\n",
    "print()\n",
    "\n",
    "print('Begin RF_20 Implementation...')\n",
    "\n",
    "# 1. Create the  model object below and assign to variable 'rf_model'\n",
    "rf_20_model = RandomForestRegressor(n_estimators = 20, max_depth = 32)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_20_model.fit(X_train, y_train)\n",
    "\n",
    "# scoring\n",
    "y_rf_pred_20 = rf_20_model.predict(X_test)\n",
    "\n",
    "rf_rmse_20 = mean_squared_error(y_test, y_rf_pred_20, squared=False)\n",
    "\n",
    "rf_r2_20 = r2_score(y_test, y_dt_pred)\n",
    "\n",
    "                   \n",
    "print('[RF_20] Root Mean Squared Error: {:.10f}'.format(rf_rmse_20))\n",
    "print('[RF_20] R2: {:.10f}'.format(rf_r2_20))    \n",
    "\n",
    "print()\n",
    "    \n",
    "print('Begin RF_50 Implementation...')\n",
    "\n",
    "# 1. Create the  model object below and assign to variable 'rf_model'\n",
    "rf_50_model = RandomForestRegressor(n_estimators = 20, max_depth = 32)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_50_model.fit(X_train, y_train)\n",
    "\n",
    "# scoring\n",
    "y_rf_pred_50 = rf_50_model.predict(X_test)\n",
    "\n",
    "rf_rmse_50 = mean_squared_error(y_test, y_rf_pred_50, squared=False)\n",
    "\n",
    "rf_r2_50 = r2_score(y_test, y_dt_pred)\n",
    "\n",
    "                   \n",
    "print('[RF_50] Root Mean Squared Error: {:.10f}'.format(rf_rmse_50))\n",
    "print('[RF_50] R2: {:.10f}'.format(rf_r2_50))    \n",
    "\n",
    "print()\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab0f31",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca5f30",
   "metadata": {},
   "source": [
    "### <font color = #FE0BEC><b> RMSE tells how well a regression model can predict the value of a response variable in absolute terms (standard Deviation in residuals)\n",
    "\n",
    "### $ R^2 $ tells how well the predictor variables can explain the variation in the response variable.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "RMSE_Results = [lr_rmse, dt_rmse, rf_rmse_100, rf_rmse_50, rf_rmse_20]\n",
    "R2_Results = [lr_r2, dt_r2, rf_r2_100, rf_r2_50, rf_r2_20]\n",
    "labels = ['LR', 'DT', 'RF_100', 'RF_50', 'RF_20']\n",
    "\n",
    "rg= np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "plt.bar(rg, RMSE_Results, width, label=\"RMSE\")\n",
    "plt.bar(rg+width, R2_Results, width, label='R2')\n",
    "plt.xticks(rg + width/2, labels)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.01))  # Specify the desired tick positions and labels\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.grid(color='green', linewidth=1.5, axis='both', alpha=0.5)\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83234a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd52253d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
